#!/usr/bin/env python3
"""
è®­ç»ƒé—®é¢˜å¿«é€Ÿè¯Šæ–­è„šæœ¬
"""

def analyze_training_metrics():
    """åŸºäºæä¾›çš„è®­ç»ƒæ—¥å¿—åˆ†æé—®é¢˜"""
    
    print("ğŸ” è®­ç»ƒçŠ¶æ€å¿«é€Ÿè¯Šæ–­")
    print("=" * 60)
    
    # ä»ç”¨æˆ·æä¾›çš„è®­ç»ƒæ—¥å¿—
    metrics = {
        "ep_rew_mean": -5.94,
        "direction_accuracy": 0.338,
        "adaptive_weights": {
            "policy": 0.164,
            "value": 0.144, 
            "entropy": 0.00707,
            "direction": 0.000242
        },
        "losses": {
            "policy": 0.0893,
            "value": 0.00233,
            "entropy": -0.000512,
            "direction": 1.75
        },
        "cov": {
            "policy": 10.7,
            "value": 31.3,
            "entropy": 23.1,
            "direction": 0.0788
        },
        "explained_variance": -3.09,
        "approx_kl": 3.472087e-08,
        "clip_fraction": 0
    }
    
    print("ğŸ“Š å…³é”®æŒ‡æ ‡åˆ†æ:")
    
    # 1. ä»»åŠ¡è¡¨ç°åˆ†æ
    print(f"\nğŸ® ä»»åŠ¡è¡¨ç°:")
    if metrics["ep_rew_mean"] < 0:
        print(f"  âŒ å¹³å‡å¥–åŠ±: {metrics['ep_rew_mean']:.2f} (è´Ÿå€¼ï¼Œä»»åŠ¡å¤±è´¥)")
        severity = "ä¸¥é‡"
    elif metrics["ep_rew_mean"] < 10:
        print(f"  âš ï¸ å¹³å‡å¥–åŠ±: {metrics['ep_rew_mean']:.2f} (è¾ƒä½)")
        severity = "ä¸­ç­‰"
    else:
        print(f"  âœ… å¹³å‡å¥–åŠ±: {metrics['ep_rew_mean']:.2f} (è‰¯å¥½)")
        severity = "è½»å¾®"
    
    # 2. æƒé‡åˆ†å¸ƒåˆ†æ
    print(f"\nâš–ï¸ æƒé‡åˆ†å¸ƒåˆ†æ:")
    weights = metrics["adaptive_weights"]
    total_weight = sum(weights.values())
    
    for name, weight in weights.items():
        percentage = weight / total_weight * 100
        if name == "entropy" and percentage < 2:
            status = "âŒ è¿‡ä½(æ¢ç´¢ä¸è¶³)"
        elif name == "direction" and percentage < 1:
            status = "âŒ è¿‡ä½(è¾…åŠ©ä»»åŠ¡å¤±æ•ˆ)"
        elif percentage > 50:
            status = "âš ï¸ è¿‡é«˜(å¯èƒ½ä¸»å¯¼)"
        else:
            status = "âœ… æ­£å¸¸"
        
        print(f"  {name:9}: {weight:.6f} ({percentage:4.1f}%) {status}")
    
    # 3. æ¢ç´¢çŠ¶æ€åˆ†æ
    print(f"\nğŸ² æ¢ç´¢çŠ¶æ€:")
    entropy_loss = abs(metrics["losses"]["entropy"])
    if entropy_loss < 0.001:
        print(f"  âŒ Entropy loss: {entropy_loss:.6f} (å‡ ä¹æ— æ¢ç´¢)")
    elif entropy_loss < 0.01:
        print(f"  âš ï¸ Entropy loss: {entropy_loss:.6f} (æ¢ç´¢ä¸è¶³)")
    else:
        print(f"  âœ… Entropy loss: {entropy_loss:.6f} (æ¢ç´¢å……åˆ†)")
    
    # 4. æ–¹å‘å­¦ä¹ åˆ†æ  
    print(f"\nğŸ§­ æ–¹å‘å­¦ä¹ :")
    dir_acc = metrics["direction_accuracy"]
    random_acc = 1/9  # 9ä¸ªæ–¹å‘çš„éšæœºå‡†ç¡®ç‡
    
    if dir_acc <= random_acc * 1.2:  # å‡ ä¹ç­‰äºéšæœº
        print(f"  âŒ Direction accuracy: {dir_acc:.3f} (æ¥è¿‘éšæœº: {random_acc:.3f})")
    elif dir_acc < 0.5:
        print(f"  âš ï¸ Direction accuracy: {dir_acc:.3f} (æœ‰æ”¹å–„ä½†ä¸è¶³)")
    else:
        print(f"  âœ… Direction accuracy: {dir_acc:.3f} (è‰¯å¥½)")
    
    # 5. è®­ç»ƒç¨³å®šæ€§åˆ†æ
    print(f"\nğŸ“ˆ è®­ç»ƒç¨³å®šæ€§:")
    high_cov_count = sum(1 for cov in metrics["cov"].values() if cov > 20)
    
    if high_cov_count >= 2:
        print(f"  âŒ {high_cov_count}ä¸ªæŸå¤±å˜å¼‚ç³»æ•°>20 (è®­ç»ƒä¸ç¨³å®š)")
    elif high_cov_count == 1:
        print(f"  âš ï¸ {high_cov_count}ä¸ªæŸå¤±å˜å¼‚ç³»æ•°>20 (è½»å¾®ä¸ç¨³å®š)")
    else:
        print(f"  âœ… å˜å¼‚ç³»æ•°æ­£å¸¸ (è®­ç»ƒç¨³å®š)")
    
    if metrics["explained_variance"] < 0:
        print(f"  âŒ Explained variance: {metrics['explained_variance']:.2f} (ä»·å€¼å‡½æ•°å¾ˆå·®)")
    
    # 6. ç­–ç•¥æ›´æ–°åˆ†æ
    print(f"\nğŸ”„ ç­–ç•¥æ›´æ–°:")
    if metrics["approx_kl"] < 1e-6:
        print(f"  âŒ KLæ•£åº¦: {metrics['approx_kl']:.2e} (ç­–ç•¥å‡ ä¹ä¸æ›´æ–°)")
    elif metrics["clip_fraction"] == 0:
        print(f"  âš ï¸ Clip fraction: 0 (æ›´æ–°å¹…åº¦å¾ˆå°)")
    
    return severity

def provide_solutions(severity):
    """æ ¹æ®é—®é¢˜ä¸¥é‡ç¨‹åº¦æä¾›è§£å†³æ–¹æ¡ˆ"""
    
    print(f"\nğŸ”§ è§£å†³æ–¹æ¡ˆ (é—®é¢˜ä¸¥é‡ç¨‹åº¦: {severity})")
    print("=" * 60)
    
    if severity == "ä¸¥é‡":
        print("ğŸš¨ ç«‹å³è¡ŒåŠ¨ - è®­ç»ƒåŸºæœ¬å¤±æ•ˆ:")
        print("  1. åœæ­¢å½“å‰è®­ç»ƒ")
        print("  2. å¢åŠ æœ€å°æƒé‡ä¿æŠ¤: min_weight = 0.1")
        print("  3. å¤§å¹…æå‡æ¢ç´¢: ent_coef = 0.08")
        print("  4. å¢å¼ºæ–¹å‘å­¦ä¹ : direction_weight = 0.4")
        print("  5. é‡æ–°å¼€å§‹è®­ç»ƒ")
        
        print("\nğŸ¯ å…·ä½“ä¿®æ”¹:")
        print("  - ä½¿ç”¨ improved_training_config_v2.py")
        print("  - æˆ–è€…æ‰‹åŠ¨ä¿®æ”¹å‚æ•°é‡æ–°è®­ç»ƒ")
        
    elif severity == "ä¸­ç­‰":
        print("âš ï¸ è°ƒæ•´ä¼˜åŒ–:")
        print("  1. å¢åŠ explorationæƒé‡")
        print("  2. æ£€æŸ¥direction learningæ•ˆæœ")
        print("  3. é™ä½norm_decayæé«˜é€‚åº”æ€§")
        
    else:
        print("âœ… å¾®è°ƒå³å¯:")
        print("  1. è§‚å¯Ÿå‡ ä¸ªepochçœ‹æ˜¯å¦æ”¹å–„")
        print("  2. å¯èƒ½åªéœ€è¦æ›´å¤šè®­ç»ƒæ—¶é—´")

def show_expected_improvements():
    """æ˜¾ç¤ºä¿®å¤åçš„é¢„æœŸæ”¹å–„"""
    
    print(f"\nğŸ“ˆ ä¿®å¤åé¢„æœŸæ”¹å–„")
    print("=" * 60)
    
    improvements = [
        ("ep_rew_mean", "-5.94", "> 0", "ä»»åŠ¡å¼€å§‹æˆåŠŸ"),
        ("adaptive_weights/entropy", "0.007", "> 0.02", "æ¢å¤æ¢ç´¢"),
        ("adaptive_weights/direction", "0.0002", "> 0.05", "æ–¹å‘å­¦ä¹ ç”Ÿæ•ˆ"),
        ("direction_accuracy", "33.8%", "> 40%", "ç©ºé—´æ„ŸçŸ¥æå‡"),
        ("entropy_loss", "~0", "> 0.01", "æ¢ç´¢æ´»è·ƒ"),
        ("explained_variance", "-3.09", "> 0", "ä»·å€¼å‡½æ•°æ”¹å–„")
    ]
    
    print(f"{'æŒ‡æ ‡':<25} {'å½“å‰':<10} {'ç›®æ ‡':<10} {'å«ä¹‰'}")
    print("-" * 60)
    for metric, current, target, meaning in improvements:
        print(f"{metric:<25} {current:<10} {target:<10} {meaning}")

if __name__ == "__main__":
    severity = analyze_training_metrics()
    provide_solutions(severity)
    show_expected_improvements()
    
    print(f"\nğŸ’¡ å…³é”®å»ºè®®:")
    print("1. å½“å‰è®­ç»ƒå·²é™·å…¥å±€éƒ¨æœ€ä¼˜ï¼Œå»ºè®®é‡æ–°å¼€å§‹")
    print("2. ä½¿ç”¨ä¿®å¤åçš„é…ç½®: improved_training_config_v2.py")
    print("3. å¯†åˆ‡ç›‘æ§å‰50æ¬¡è¿­ä»£çš„æŒ‡æ ‡å˜åŒ–")
    print("4. å¦‚æœä»æœ‰é—®é¢˜ï¼Œå¯è¿›ä¸€æ­¥è°ƒæ•´å‚æ•°")