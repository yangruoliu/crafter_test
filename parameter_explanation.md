# PPO训练参数详细说明

## 🎯 核心PPO参数

### 1. **学习率相关**
```python
learning_rate=3e-4  # 0.0003
```
- **含义**: 梯度下降的步长大小
- **作用**: 控制模型参数更新的幅度
- **典型范围**: 1e-5 到 1e-3
- **过大**: 训练不稳定，可能发散
- **过小**: 训练缓慢，可能陷入局部最优

### 2. **经验收集参数**
```python
n_steps=4096        # 每次更新前收集的经验步数
batch_size=512      # 每个mini-batch的大小
n_epochs=3          # 每次收集数据后的训练轮数
```

#### `n_steps` (rollout步数)
- **含义**: 智能体与环境交互收集多少步经验后进行一次策略更新
- **作用**: 平衡样本效率和训练稳定性
- **4096**: 收集4096步经验，然后用这些数据训练模型

#### `batch_size` (批次大小)
- **含义**: 每次梯度更新使用的样本数量
- **作用**: 影响梯度估计的准确性和计算效率
- **512**: 每次从4096个样本中随机选择512个进行训练

#### `n_epochs` (训练轮数)
- **含义**: 对同一批收集的数据重复训练多少次
- **作用**: 提高数据利用率，但过多可能导致过拟合
- **3**: 对每批数据训练3轮

### 3. **奖励折扣参数**
```python
gamma=0.95          # 奖励折扣因子
gae_lambda=0.65     # GAE优势估计的lambda参数
```

#### `gamma` (折扣因子)
- **含义**: 未来奖励相对于当前奖励的重要性
- **0.95**: 10步后的奖励价值是当前的 0.95^10 ≈ 0.6
- **接近1**: 更重视长期奖励
- **接近0**: 更重视短期奖励

#### `gae_lambda` (GAE参数)
- **含义**: 控制优势估计中偏差和方差的权衡
- **0.65**: 平衡偏差和方差
- **接近1**: 低偏差，高方差
- **接近0**: 高偏差，低方差

### 4. **PPO特有参数**
```python
clip_range=0.2      # PPO裁剪范围
```
- **含义**: 限制策略更新的幅度，防止过度更新
- **0.2**: 新旧策略比值被限制在 [0.8, 1.2] 范围内
- **作用**: 确保训练稳定性，避免策略崩溃

## 🔧 损失函数权重参数

### 1. **基础权重**
```python
ent_coef=0.02       # 熵损失系数
vf_coef=0.3         # 价值函数损失系数
direction_weight=0.2 # 方向预测损失权重
```

#### `ent_coef` (熵系数)
- **含义**: 鼓励策略探索的程度
- **作用**: 防止策略过早收敛到次优解
- **0.02**: 在总损失中熵损失占2%的基础权重
- **过大**: 过度探索，训练不稳定
- **过小**: 探索不足，容易陷入局部最优

#### `vf_coef` (价值函数系数)
- **含义**: 价值函数训练的重要性
- **作用**: 平衡策略学习和价值估计
- **0.3**: 价值损失在总损失中的基础权重
- **过大**: 价值函数过拟合，策略学习受影响
- **过小**: 价值估计不准确，影响优势计算

#### `direction_weight` (方向预测权重)
- **含义**: 辅助任务(方向预测)的重要性
- **作用**: 帮助模型学习空间感知能力
- **0.2**: 方向预测损失的基础权重

### 2. **正则化参数**
```python
max_grad_norm=0.5   # 梯度裁剪阈值
```
- **含义**: 防止梯度爆炸的保护机制
- **0.5**: 梯度范数超过0.5时进行裁剪
- **作用**: 提高训练稳定性

## 🎛️ 损失归一化参数

### 1. **归一化控制**
```python
loss_normalization=True  # 是否启用损失归一化
norm_decay=0.95         # 指数移动平均衰减因子
```

#### `loss_normalization`
- **含义**: 是否使用我们实现的损失归一化机制
- **True**: 启用归一化，解决不同损失量级差异问题
- **False**: 使用原始权重，可能存在量级不匹配

#### `norm_decay`
- **含义**: 计算移动平均时的衰减因子
- **0.95**: 历史数据权重为95%，新数据权重为5%
- **接近1**: 更平滑，对新数据反应慢
- **接近0**: 对新数据反应快，但可能不稳定

## 📊 损失归一化工作原理

### 1. **移动平均计算**
```python
# 每个损失的移动平均
policy_loss_ma = 0.95 * old_ma + 0.05 * current_loss
```

### 2. **变异系数计算**
```python
# 变异系数 = 标准差 / |平均值|
cov = sqrt(variance) / abs(moving_average)
```

### 3. **自适应权重**
```python
# 变异系数高的损失获得更多权重
adaptive_weight = (cov / total_cov) * base_weight
```

### 4. **最终损失**
```python
total_loss = (adaptive_policy_weight * policy_loss_norm + 
              adaptive_entropy_weight * entropy_loss_norm + 
              adaptive_value_weight * value_loss_norm + 
              adaptive_direction_weight * direction_loss_norm)
```

## 🎯 参数调优建议

### 1. **探索vs利用平衡**
- **更多探索**: 增加 `ent_coef` (0.01 → 0.03)
- **更多利用**: 减少 `ent_coef` (0.02 → 0.005)

### 2. **学习稳定性**
- **更稳定**: 减少 `learning_rate` 或 `clip_range`
- **更快学习**: 增加 `n_epochs` 但注意过拟合

### 3. **辅助任务平衡**
- **方向预测重要**: 增加 `direction_weight`
- **主任务优先**: 减少 `direction_weight`

### 4. **归一化调优**
- **快速适应**: 减少 `norm_decay` (0.95 → 0.9)
- **更平滑**: 增加 `norm_decay` (0.95 → 0.99)