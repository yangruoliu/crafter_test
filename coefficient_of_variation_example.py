#!/usr/bin/env python3
"""
å˜å¼‚ç³»æ•° (Coefficient of Variation) å®ä¾‹æ¼”ç¤º
"""

import numpy as np
import matplotlib.pyplot as plt

def demonstrate_coefficient_of_variation():
    """æ¼”ç¤ºå˜å¼‚ç³»æ•°çš„å«ä¹‰å’Œè®¡ç®—"""
    
    print("ğŸ” å˜å¼‚ç³»æ•° (Coefficient of Variation) è¯¦ç»†è§£é‡Š")
    print("=" * 60)
    
    # ç¤ºä¾‹1: ä¸åŒå˜å¼‚ç¨‹åº¦çš„æ•°æ®
    print("\nğŸ“Š ç¤ºä¾‹1: ä¸åŒå˜å¼‚ç¨‹åº¦çš„æŸå¤±æ•°æ®")
    
    # ç¨³å®šçš„æŸå¤± (ä½å˜å¼‚)
    stable_losses = [1.0, 1.1, 0.9, 1.05, 0.95, 1.02, 0.98, 1.03, 0.97, 1.01]
    
    # ä¸ç¨³å®šçš„æŸå¤± (é«˜å˜å¼‚)  
    unstable_losses = [1.0, 2.5, 0.3, 1.8, 0.1, 2.2, 0.5, 1.9, 0.2, 2.1]
    
    def calculate_cov(data):
        mean = np.mean(data)
        std = np.std(data)
        cov = std / abs(mean) if mean != 0 else 0
        return mean, std, cov
    
    stable_mean, stable_std, stable_cov = calculate_cov(stable_losses)
    unstable_mean, unstable_std, unstable_cov = calculate_cov(unstable_losses)
    
    print(f"ç¨³å®šæŸå¤±:")
    print(f"  æ•°æ®: {stable_losses}")
    print(f"  å¹³å‡å€¼: {stable_mean:.3f}")
    print(f"  æ ‡å‡†å·®: {stable_std:.3f}")
    print(f"  å˜å¼‚ç³»æ•°: {stable_cov:.3f} (ä½å˜å¼‚ - ç¨³å®š)")
    
    print(f"\nä¸ç¨³å®šæŸå¤±:")
    print(f"  æ•°æ®: {unstable_losses}")
    print(f"  å¹³å‡å€¼: {unstable_mean:.3f}")
    print(f"  æ ‡å‡†å·®: {unstable_std:.3f}")
    print(f"  å˜å¼‚ç³»æ•°: {unstable_cov:.3f} (é«˜å˜å¼‚ - ä¸ç¨³å®š)")
    
    # ç¤ºä¾‹2: ä½ çš„è®­ç»ƒæ—¥å¿—ä¸­çš„å®é™…æ•°æ®
    print(f"\nğŸ“ˆ ç¤ºä¾‹2: ä½ çš„è®­ç»ƒæ—¥å¿—åˆ†æ")
    print("æ ¹æ®ä½ æä¾›çš„è®­ç»ƒæ—¥å¿—:")
    
    # ä»ä½ çš„æ—¥å¿—ä¸­æå–çš„æ•°æ®
    training_data = {
        "policy": {"ma": -4.85, "cov": -0.787},  # åŸå§‹æœ‰é—®é¢˜çš„å€¼
        "value": {"ma": 48.5, "cov": 95.1},     # åŸå§‹æœ‰é—®é¢˜çš„å€¼  
        "entropy": {"ma": -2.47, "cov": -0.0646}, # åŸå§‹æœ‰é—®é¢˜çš„å€¼
        "direction": {"ma": 1.58, "cov": 6.61}
    }
    
    print("åŸå§‹è®¡ç®—ç»“æœ (æœ‰é—®é¢˜):")
    for loss_type, data in training_data.items():
        print(f"  {loss_type:9}: MA={data['ma']:6.2f}, CoV={data['cov']:6.3f}")
    
    # ä¿®å¤åçš„è®¡ç®— (ä½¿ç”¨ç»å¯¹å€¼)
    print("\nä¿®å¤åçš„è®¡ç®—:")
    for loss_type, data in training_data.items():
        ma = data["ma"]
        # æ¨¡æ‹Ÿæ–¹å·®è®¡ç®— (å®é™…ä¸­æ¥è‡ªç§»åŠ¨æ–¹å·®)
        if loss_type == "value":
            var = (95.1 * abs(ma)) ** 2  # åæ¨æ–¹å·®
        else:
            var = (abs(data["cov"]) * abs(ma)) ** 2  # åæ¨æ–¹å·®
        
        std = np.sqrt(var)
        fixed_cov = std / abs(ma) if ma != 0 else 0
        
        print(f"  {loss_type:9}: MA={ma:6.2f}, CoV={fixed_cov:6.3f} (ä¿®å¤å)")

def demonstrate_adaptive_weighting():
    """æ¼”ç¤ºè‡ªé€‚åº”æƒé‡åˆ†é…"""
    
    print("\nğŸ¯ è‡ªé€‚åº”æƒé‡åˆ†é…æ¼”ç¤º")
    print("=" * 60)
    
    # æ¨¡æ‹Ÿ4ç§æŸå¤±çš„å˜å¼‚ç³»æ•°
    cov_values = {
        "policy": 0.2,      # ä½å˜å¼‚ - ç¨³å®š
        "value": 1.5,       # é«˜å˜å¼‚ - ä¸ç¨³å®š  
        "entropy": 0.1,     # å¾ˆä½å˜å¼‚ - å¾ˆç¨³å®š
        "direction": 0.8    # ä¸­ç­‰å˜å¼‚ - ä¸­ç­‰ç¨³å®š
    }
    
    # åŸºç¡€æƒé‡
    base_weights = {
        "policy": 1.0,
        "value": 0.3,
        "entropy": 0.02,
        "direction": 0.2
    }
    
    print("å˜å¼‚ç³»æ•° (CoV):")
    for loss_type, cov in cov_values.items():
        interpretation = ""
        if cov < 0.3:
            interpretation = "ç¨³å®šï¼Œéœ€è¦è¾ƒå°‘å…³æ³¨"
        elif cov < 1.0:
            interpretation = "ä¸­ç­‰å˜å¼‚ï¼Œéœ€è¦é€‚åº¦å…³æ³¨"
        else:
            interpretation = "ä¸ç¨³å®šï¼Œéœ€è¦æ›´å¤šå…³æ³¨"
        print(f"  {loss_type:9}: {cov:.3f} - {interpretation}")
    
    # è®¡ç®—è‡ªé€‚åº”æƒé‡ (ç®€åŒ–ç‰ˆæœ¬)
    total_cov = sum(cov_values.values())
    
    print(f"\nè‡ªé€‚åº”æƒé‡åˆ†é…:")
    print(f"æ€»å˜å¼‚ç³»æ•°: {total_cov:.3f}")
    
    for loss_type, cov in cov_values.items():
        base_weight = base_weights[loss_type]
        # å˜å¼‚ç³»æ•°é«˜çš„è·å¾—æ›´å¤šæƒé‡
        adaptive_weight = (cov / total_cov) * base_weight
        
        print(f"  {loss_type:9}: åŸºç¡€æƒé‡={base_weight:.3f}, è‡ªé€‚åº”æƒé‡={adaptive_weight:.4f}")

def demonstrate_loss_normalization():
    """æ¼”ç¤ºæŸå¤±å½’ä¸€åŒ–è¿‡ç¨‹"""
    
    print("\nâš–ï¸ æŸå¤±å½’ä¸€åŒ–æ¼”ç¤º")
    print("=" * 60)
    
    # ä¸åŒé‡çº§çš„æŸå¤±
    current_losses = {
        "policy": 1.2,
        "value": 45.8,      # å¾ˆå¤§çš„å€¼
        "entropy": -2.3,    # è´Ÿå€¼
        "direction": 1.7
    }
    
    # ç§»åŠ¨å¹³å‡ (å†å²ç»Ÿè®¡)
    moving_averages = {
        "policy": 1.0,
        "value": 48.5,
        "entropy": -2.47,
        "direction": 1.58
    }
    
    print("åŸå§‹æŸå¤±å€¼ (é‡çº§å·®å¼‚å¾ˆå¤§):")
    for loss_type, loss in current_losses.items():
        print(f"  {loss_type:9}: {loss:6.2f}")
    
    print("\nç§»åŠ¨å¹³å‡å€¼:")
    for loss_type, ma in moving_averages.items():
        print(f"  {loss_type:9}: {ma:6.2f}")
    
    print("\nå½’ä¸€åŒ–åçš„æŸå¤± (loss / |moving_average|):")
    normalized_losses = {}
    for loss_type, loss in current_losses.items():
        ma = moving_averages[loss_type]
        normalized = loss / abs(ma) if ma != 0 else 0
        normalized_losses[loss_type] = normalized
        print(f"  {loss_type:9}: {loss:6.2f} / |{ma:6.2f}| = {normalized:.3f}")
    
    print("\nğŸ“ å½’ä¸€åŒ–çš„å¥½å¤„:")
    print("  1. æ‰€æœ‰æŸå¤±éƒ½åœ¨ç›¸ä¼¼çš„é‡çº§ä¸Š (æ¥è¿‘1.0)")
    print("  2. æƒé‡è®¾ç½®å˜å¾—æœ‰æ„ä¹‰")
    print("  3. é¿å…å¤§å€¼æŸå¤±ä¸»å¯¼è®­ç»ƒ")

if __name__ == "__main__":
    demonstrate_coefficient_of_variation()
    demonstrate_adaptive_weighting()
    demonstrate_loss_normalization()
    
    print("\nğŸ¯ æ€»ç»“")
    print("=" * 60)
    print("1. å˜å¼‚ç³»æ•° = æ ‡å‡†å·® / |å¹³å‡å€¼|")
    print("2. é«˜å˜å¼‚ç³»æ•° â†’ æŸå¤±ä¸ç¨³å®š â†’ éœ€è¦æ›´å¤šå…³æ³¨")
    print("3. æŸå¤±å½’ä¸€åŒ–è§£å†³ä¸åŒæŸå¤±é‡çº§å·®å¼‚é—®é¢˜")
    print("4. è‡ªé€‚åº”æƒé‡æ ¹æ®æŸå¤±ç¨³å®šæ€§åŠ¨æ€è°ƒæ•´")
    print("5. æœ€ç»ˆç›®æ ‡: è®©æ‰€æœ‰æŸå¤±éƒ½å¾—åˆ°åˆé€‚çš„å…³æ³¨")